def _log_id_to_index(self, log_id: int):
    # TODO: This function is only for internal use. Get lock before calling this function.
    # self.log_entries是一个dict的enqueue，新的log会被append进去，每条数据会有一个"_id"字段，保存该log的ID。
    # 实现该函数，通过log_id找到对应的log index。理论上，这个deque中的log其_id是连续和有序的。可以使用优化的方法加速查找。
    pass



接下来我需要一步步重构这一段代码，先按我的要求，参考已有代码重新实现以下新函数，先不要改动旧函数和调用新编写的函数。


将缓存log的逻辑抽取成一个独立的函数，包括正确将加入的log放入缓存正确的位置（根据'_id'检查插入点和自动排列，保证列表内的log正序）。
同时维护当前缓存log的id上下界，用做后续更新的基准。
今后无论通过'/logger/api/modules'还是'/logger/api/stream'接口接收到的数据都由该函数汇总保存。


同时将log更新到列表的功能也单独抽取也一个独立的函数，它维护自己显示的log的id上下界(cache_id_min, cache_id_max)。该函数更新显示列表**只基于log缓存**。
更新的策略是检查自身显示的上下界和缓存上下界的差异。从面决定在头部或尾部正确插入数据。
在显示前需要应用filter以筛选需要显示的内容。
注意该函数只依赖于缓存，且实时应用filter。不接受通过传入的log列表更新数据。有需要更新显示的请求只能通过该函数。


再将从'/logger/api/modules'取数据的接口也抽取也一个独立函数，接受一个count参数，如果为正。则start=cache_id_max, limit = count，如果为负，则start = (cache_id_min - abs(count), limit = abs(count))。
start与until必须与上下界接壤，如果不是，则调整到接壤，从而确保获取的数据能和缓存数据连续。获取到的数据直接通过上面的函数加入缓存。
注意：不需要fiter参数。




接下来对于原始代码中，需要改为调用新实现函数的部分，改为调用新函数，并重新输出修改后函数的实现。






接下来我将给出一段前端代码，帮我修复一个问题：

当log的数量巨大，浏览器占用内存也巨大，而且虽然log数据持续接收且更新，但页面几乎不刷新。
我希望在两处增加限制：

1. Log缓存，通过一个变量（预留给后续配置）控制其上限，达到上限后丢弃最早的log，且更新log的id上下界。
2. 该变量同时控制列表显示的上限，达到上限后向上滚动更新功能无效，且新项目的加入会同时移除最顶上（旧的）列表项。








